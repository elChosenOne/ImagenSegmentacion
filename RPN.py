# import the necessary packages
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.applications import imagenet_utils
from tensorflow.keras.preprocessing.image import img_to_array
from imutils.object_detection import non_max_suppression
import numpy as np
import argparse
import cv2
import time
from PIL import Image
import FeatureVector as FV

def selective_search(image, method="fast"):
	# initialize OpenCV's selective search implementation and set the
	# input image
    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    ss.setBaseImage(image)
	# check to see if we are using the *fast* but *less accurate* version
	# of selective search
    if method == "fast":
        print("Iniciando metodo rapido")
        ss.switchToSelectiveSearchFast()
	# otherwise we are using the *slower* but *more accurate* version
    else:
        print("Iniciando metodo calidad")
        ss.switchToSelectiveSearchQuality()
    # run selective search on the input image
    t1 = time.time()
    rects = ss.process()
    t2 = time.time()
    print("Tiempo = ", t2-t1)
	# return the region proposal bounding boxes
    return rects
    
# load ResNet from disk (with weights pre-trained on ImageNet)
print("[INFO] loading ResNet...")
model = ResNet50(weights="imagenet")
# load the input image from disk and grab its dimensions
image = cv2.imread(r'.\Imagenes\IMG1I.jpg')
#image = Image.open(".\Imagenes\\IMG1I.jpg")


(H, W) = image.shape[:2]
print("H = ", H, " W = ", W)

AR = [4/3, 5/3, 5/4, 16/9, 16/10, 17/10]
ARc = [(4, 3), (5, 3), (5, 4), (16, 9), (16, 10), (17, 10)]
Div = max(H, W)/min(H, W)

for i in range(len(AR)):
    AR[i] = abs(AR[i]-Div)

ARval = np.argmin(AR)
#clone = image.copy()
#cv2.imshow("Imagen", clone)

H = int(np.floor(ARc[ARval][1]*(1024/ARc[ARval][0])))

image = cv2.resize(image, (1024, H))
(H, W) = image.shape[:2]
print("H = ", H, " W = ", W)

# run selective search on the input image
print("[INFO] performing selective search with fast method...")
rects = selective_search(image, method="fast")
print("[INFO] {} regions found by selective search".format(len(rects)))
# initialize the list of region proposals that we'll be classifying
# along with their associated bounding boxes
proposals = []
boxes = []

# loop over the region proposal bounding box coordinates generated by
# running selective search
for (x, y, w, h) in rects:
	# if the width or height of the region is less than 10% of the
	# image width or height, ignore it (i.e., filter out small
	# objects that are likely false-positives)
    if w / float(W) < 0.1 or h / float(H) < 0.1:
        continue
	# extract the region from the input image, convert it from BGR to
	# RGB channel ordering, and then resize it to 224x224 (the input
	# dimensions required by our pre-trained CNN)
    roi = image[y:y + h, x:x + w]
    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
    roi = cv2.resize(roi, (224, 224))
	# further preprocess by the ROI
    roi = img_to_array(roi)
    roi = preprocess_input(roi)
	# update our proposals and bounding boxes lists
    proposals.append(roi)
    boxes.append((x, y, w, h))

print("[INFO] {} filtred regions found by selective search".format(len(boxes)))

FV.ProbarRed()